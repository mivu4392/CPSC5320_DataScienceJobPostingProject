{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['Sentiment'] = df['Descriptions_clean'].apply(lambda x: sia.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract negative, positive, and neutral scores\n",
    "df['Negative Score'] = df['Sentiment'].apply(lambda x: x['neg'])\n",
    "df['Positive Score'] = df['Sentiment'].apply(lambda x: x['pos'])\n",
    "df['Neutral Score'] = df['Sentiment'].apply(lambda x: x['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Title  Negative Score  Positive Score  Neutral Score\n",
      "0                       Others           0.006           0.138          0.856\n",
      "1               Data Scientist           0.033           0.100          0.867\n",
      "2               Data Scientist           0.033           0.100          0.867\n",
      "3             Business Analyst           0.025           0.132          0.843\n",
      "4                Data Engineer           0.000           0.143          0.857\n",
      "..                         ...             ...             ...            ...\n",
      "325           Business Analyst           0.000           0.068          0.932\n",
      "326             Data Scientist           0.016           0.166          0.818\n",
      "327             Data Scientist           0.050           0.234          0.717\n",
      "328  Machine Learning Engineer           0.009           0.176          0.815\n",
      "329  Machine Learning Engineer           0.009           0.176          0.815\n",
      "\n",
      "[330 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the scores for each title\n",
    "print(df[['Title', 'Negative Score', 'Positive Score', 'Neutral Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group scores by title\n",
    "grouped_df = df.groupby('Title').agg({'Negative Score': 'mean', 'Positive Score': 'mean', 'Neutral Score': 'mean'}).reset_index()\n",
    "grouped_df = grouped_df.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Others' category\n",
    "grouped_df = grouped_df[grouped_df['Title'] != 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by title\n",
    "grouped_df = grouped_df.sort_values('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store words by title\n",
    "word_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize words by title\n",
    "for title, description in zip(df['Title'], df['Descriptions_clean']):\n",
    "    tokens = word_tokenize(description)\n",
    "    negative_words = set()\n",
    "    positive_words = set()\n",
    "    for token in tokens:\n",
    "        if sia.polarity_scores(token)['compound'] < 0:\n",
    "            negative_words.add(token)\n",
    "        elif sia.polarity_scores(token)['compound'] > 0:\n",
    "            positive_words.add(token)\n",
    "    \n",
    "    if title not in word_data:\n",
    "        word_data[title] = {'Negative Words': list(negative_words), 'Positive Words': list(positive_words)}\n",
    "    else:\n",
    "        word_data[title]['Negative Words'].extend(list(negative_words))\n",
    "        word_data[title]['Positive Words'].extend(list(positive_words))\n",
    "     # Remove duplicates from the word lists\n",
    "    word_data[title]['Negative Words'] = list(set(word_data[title]['Negative Words']))\n",
    "    word_data[title]['Positive Words'] = list(set(word_data[title]['Positive Words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words to JSON\n",
    "with open('words.json', 'w') as file:\n",
    "    json.dump(word_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grouped data to JSON\n",
    "result = grouped_df.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON to a file\n",
    "with open('scores.json', 'w') as file:\n",
    "    json.dump(json.loads(result), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
