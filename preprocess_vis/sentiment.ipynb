{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/felixvu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['Sentiment'] = df['Descriptions_clean'].apply(lambda x: sia.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract negative, positive, and neutral scores\n",
    "df['Negative Score'] = df['Sentiment'].apply(lambda x: x['neg'])\n",
    "df['Positive Score'] = df['Sentiment'].apply(lambda x: x['pos'])\n",
    "df['Neutral Score'] = df['Sentiment'].apply(lambda x: x['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Title  Negative Score  Positive Score  Neutral Score\n",
      "0                       Others           0.006           0.138          0.856\n",
      "1               Data Scientist           0.033           0.100          0.867\n",
      "2               Data Scientist           0.033           0.100          0.867\n",
      "3             Business Analyst           0.025           0.132          0.843\n",
      "4                Data Engineer           0.000           0.143          0.857\n",
      "..                         ...             ...             ...            ...\n",
      "325           Business Analyst           0.000           0.068          0.932\n",
      "326             Data Scientist           0.016           0.166          0.818\n",
      "327             Data Scientist           0.050           0.234          0.717\n",
      "328  Machine Learning Engineer           0.009           0.176          0.815\n",
      "329  Machine Learning Engineer           0.009           0.176          0.815\n",
      "\n",
      "[330 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the scores for each title\n",
    "print(df[['Title', 'Negative Score', 'Positive Score', 'Neutral Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group scores by title\n",
    "grouped_df = df.groupby('Title').agg({'Negative Score': 'mean', 'Positive Score': 'mean', 'Neutral Score': 'mean'}).reset_index()\n",
    "grouped_df = grouped_df.round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Others' category\n",
    "grouped_df = grouped_df[grouped_df['Title'] != 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by title\n",
    "grouped_df = grouped_df.sort_values('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store words by title\n",
    "word_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define words to be excluded\n",
    "excluded_words = ['a', 'an', 'and', 'are', 'as', 'at', 'be', 'by', 'for', 'from', 'has', 'he', 'in', 'is', 'it', 'its', 'of', 'on', 'or', 'that', 'the', 'to', 'was', 'were', 'will', 'with']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize words by title\n",
    "for title, description in zip(df['Title'], df['Descriptions_clean']):\n",
    "    tokens = word_tokenize(description)\n",
    "    negative_words = []\n",
    "    positive_words = []\n",
    "    neutral_words = []\n",
    "    for token in tokens:\n",
    "        # Skip single-letter words\n",
    "        if len(token) == 1:\n",
    "            continue\n",
    "        # Skip excluded words\n",
    "        if token.lower() in excluded_words:\n",
    "            continue\n",
    "        \n",
    "        score = sia.polarity_scores(token)['compound']\n",
    "        if score < 0:\n",
    "            negative_words.append(token)\n",
    "        elif score > 0:\n",
    "            positive_words.append(token)\n",
    "        else:\n",
    "            neutral_words.append(token)\n",
    "    \n",
    "    if title not in word_data:\n",
    "        word_data[title] = {'Negative Words': negative_words, 'Positive Words': positive_words, 'Neutral Words': neutral_words}\n",
    "    else:\n",
    "        word_data[title]['Negative Words'].extend(negative_words)\n",
    "        word_data[title]['Positive Words'].extend(positive_words)\n",
    "        word_data[title]['Neutral Words'].extend(neutral_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort words by counts in descending order\n",
    "# for title in word_data:\n",
    "#     negative_word_counts = Counter(word_data[title]['Negative Words'])\n",
    "#     positive_word_counts = Counter(word_data[title]['Positive Words'])\n",
    "#     neutral_word_counts = Counter(word_data[title]['Neutral Words'])\n",
    "    \n",
    "#     word_data[title]['Negative Words'] = sorted(negative_word_counts.keys(), key=lambda x: negative_word_counts[x], reverse=True)\n",
    "#     word_data[title]['Positive Words'] = sorted(positive_word_counts.keys(), key=lambda x: positive_word_counts[x], reverse=True)\n",
    "#     word_data[title]['Neutral Words'] = sorted(neutral_word_counts.keys(), key=lambda x: neutral_word_counts[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort words by counts in descending order and keep only top 15 words\n",
    "for title in word_data:\n",
    "    negative_word_counts = Counter(word_data[title]['Negative Words'])\n",
    "    positive_word_counts = Counter(word_data[title]['Positive Words'])\n",
    "    neutral_word_counts = Counter(word_data[title]['Neutral Words'])\n",
    "    \n",
    "    word_data[title]['Negative Words'] = sorted(negative_word_counts.keys(), key=lambda x: negative_word_counts[x], reverse=True)[:15]\n",
    "    word_data[title]['Positive Words'] = sorted(positive_word_counts.keys(), key=lambda x: positive_word_counts[x], reverse=True)[:15]\n",
    "    word_data[title]['Neutral Words'] = sorted(neutral_word_counts.keys(), key=lambda x: neutral_word_counts[x], reverse=True)[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save words to JSON\n",
    "# with open('../data/word_categories_descending.json', 'w') as file:\n",
    "#     json.dump(word_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save words to JSON\n",
    "with open('../data/word_categories_descending_15.json', 'w') as file:\n",
    "    json.dump(word_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert grouped data to JSON\n",
    "result = grouped_df.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON to a file\n",
    "with open('../data/sentiment_scores.json', 'w') as file:\n",
    "    json.dump(json.loads(result), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
